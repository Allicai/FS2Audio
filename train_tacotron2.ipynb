{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21cb43c5-2192-472b-b0ea-ee0ba04e7119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting TensorFlowTTS\n",
      "  Using cached TensorFlowTTS-1.8-py3-none-any.whl.metadata (24 kB)\n",
      "INFO: pip is looking at multiple versions of tensorflowtts to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached TensorFlowTTS-1.6.1-py3-none-any.whl.metadata (23 kB)\n",
      "  Using cached TensorFlowTTS-1.6-py3-none-any.whl.metadata (23 kB)\n",
      "  Using cached TensorFlowTTS-1.1-py3-none-any.whl.metadata (22 kB)\n",
      "  Using cached TensorFlowTTS-0.11-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tensorflow-gpu>=2.3.1 (from TensorFlowTTS)\n",
      "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [44 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\vinit\\anaconda3\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\requirements.py\", line 35, in __init__\n",
      "      parsed = _parse_requirement(requirement_string)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\vinit\\anaconda3\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 64, in parse_requirement\n",
      "      return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\vinit\\anaconda3\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 82, in _parse_requirement\n",
      "      url, specifier, marker = _parse_requirement_details(tokenizer)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\vinit\\anaconda3\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 126, in _parse_requirement_details\n",
      "      marker = _parse_requirement_marker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\vinit\\anaconda3\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 147, in _parse_requirement_marker\n",
      "      tokenizer.raise_syntax_error(\n",
      "    File \"C:\\Users\\vinit\\anaconda3\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_tokenizer.py\", line 165, in raise_syntax_error\n",
      "      raise ParserSyntaxError(\n",
      "  setuptools.extern.packaging._tokenizer.ParserSyntaxError: Expected end or semicolon (after name and no valid version specifier)\n",
      "      python_version>\"3.7\"\n",
      "                    ^\n",
      "  \n",
      "  The above exception was the direct cause of the following exception:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\vinit\\AppData\\Local\\Temp\\pip-install-ui35n5su\\tensorflow-gpu_76ad10b59d7144f1ad67278e2d2b972a\\setup.py\", line 40, in <module>\n",
      "      setuptools.setup()\n",
      "    File \"C:\\Users\\vinit\\anaconda3\\Lib\\site-packages\\setuptools\\__init__.py\", line 103, in setup\n",
      "      _install_setup_requires(attrs)\n",
      "    File \"C:\\Users\\vinit\\anaconda3\\Lib\\site-packages\\setuptools\\__init__.py\", line 74, in _install_setup_requires\n",
      "      dist.parse_config_files(ignore_option_errors=True)\n",
      "    File \"C:\\Users\\vinit\\anaconda3\\Lib\\site-packages\\setuptools\\dist.py\", line 633, in parse_config_files\n",
      "      self._finalize_requires()\n",
      "    File \"C:\\Users\\vinit\\anaconda3\\Lib\\site-packages\\setuptools\\dist.py\", line 368, in _finalize_requires\n",
      "      self._normalize_requires()\n",
      "    File \"C:\\Users\\vinit\\anaconda3\\Lib\\site-packages\\setuptools\\dist.py\", line 383, in _normalize_requires\n",
      "      self.install_requires = list(map(str, _reqs.parse(install_requires)))\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\vinit\\anaconda3\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\requirements.py\", line 37, in __init__\n",
      "      raise InvalidRequirement(str(e)) from e\n",
      "  setuptools.extern.packaging.requirements.InvalidRequirement: Expected end or semicolon (after name and no valid version specifier)\n",
      "      python_version>\"3.7\"\n",
      "                    ^\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install TensorFlowTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501f6279-96d7-4721-a66c-a0f8880600d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0b1013-2e4b-4716-85a1-2eb225a1281d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vinit\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_tts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtacotron2_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_tacotron2_model\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_tts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AdamWeightDecay\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_tts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TacotronLoss\n",
      "File \u001b[1;32m~\\Documents\\Prod\\tts_model\\tacotron2_model.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Method to create an instance of the tacotron2 model we will be working with.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_tts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tacotron2\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_tts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m return_strategy\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_tacotron2_model\u001b[39m():\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_tts'"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tacotron2_model import create_tacotron2_model\n",
    "from tensorflow_tts.optimizers import AdamWeightDecay\n",
    "from tensorflow_tts.losses import TacotronLoss\n",
    "from tensorflow_tts.utils import Char2MelProcessor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafa5daf-9987-4805-b754-6b234a0116d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "# metadata.csv has two transcriptions for each audio file - split the csv by '|'.\n",
    "metadata = pd.read_csv(\"metadata.csv\", sep='|', names=[\"ID\", \"transcription1\", \"transcription2\"])\n",
    "\n",
    "# creating a new column for audio paths \n",
    "# metadata.csv contains 'ID's, which are the names of the audio files in the wavs dir\n",
    "# for example, the ID LJ001-0001 correlates to LJ001-0001.wav in the wavs folder, so we append\n",
    "# .wav to the end of the ID and get the audio\n",
    "metadata['audio_path'] = metadata['ID'].apply(lambda x: f'wavs/{x}.wav')\n",
    "\n",
    "# using train_test_split to generate training vs testing data\n",
    "train_metadata, val_metadata = train_test_split(metadata, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d776b-22e2-41c6-9942-1d849193f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7726a4-2f15-48f7-a62a-607bf6d0b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing a tacotron2 model\n",
    "tacotron2 = create_tacotron2_model()\n",
    "\n",
    "# defining our optimizer - read on the Adam optimizer from class \n",
    "optimizer = AdamWeightDecay(learning_rate=1e-4, weight_decay_rate=1e-6)\n",
    "\n",
    "# compiling the model\n",
    "tacotron2.compile(optimizer=optimizer, loss=TacotronLoss())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa45f87-6044-45be-b1d8-bee2167f45e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "history = tacotron2.fit(train_metadata[\"transcription1\"], train_metadata[\"audio_path\"],\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        epochs=EPOCHS,\n",
    "                        validation_data=(val_metadata[\"transcription1\"], val_metadata[\"audio_path\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
